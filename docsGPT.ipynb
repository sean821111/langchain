{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# requirements\\n!pip install langchain\\n!pip install openai\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# requirements\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Loader\n",
    "[Langchain PDF reference link](https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here demonstrate analyzing a product specfication from PDF file.\n",
    "'''\n",
    "\n",
    "# loader = PyPDFLoader(\"example_data/rxi-web-panel-emerson.pdf\")\n",
    "# loader = PyPDFLoader(\"example_data/HEM-6232T Manual - Omron Healthcare.pdf\")\n",
    "# loader = PyPDFLoader(\"example_data/CONDENSED CATALOG - lotek.dk.pdf\")\n",
    "loader = PyPDFLoader(\"example_data/10-04-580-SPC - Wall-Smart.pdf\")\n",
    "\n",
    "# pages = loader.load_and_split()\n",
    "\n",
    "doc = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splliter\n",
    "\n",
    "[Dcument trasformers](https://python.langchain.com/docs/modules/data_connection/document_transformers/)\n",
    "<br>\n",
    "Ë∂ÖÈï∑ÊñáÊú¨ÁöÑÂàáÂâ≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# doc = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=1000)\n",
    "pages = splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "The Embeddings class is a class designed for interfacing with text embedding models. \n",
    "<br>\n",
    "[Text embedding models(e.g. openAI, huggingface)](https://python.langchain.com/docs/modules/data_connection/text_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store openai embedding vectors\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you.\n",
    "<br>\n",
    "Vector store Êèê‰æõÂÑ≤Â≠ò‰ª•ÂèäÊ™¢Á¥¢ÈùûÁµêÊßãÂêëÈáèË≥áÊñôÔºåÈÄèÈÅé query Ê™¢Á¥¢ÊúÄÁõ∏‰ººÁöÑÂêëÈáè„ÄÇ\n",
    "\n",
    "[other langchain vector stores](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\n",
    "<br>\n",
    "[ü¶ú‚õìÔ∏è + Chroma](https://blog.langchain.dev/langchain-chroma/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Chroma, the AI-native open-source embedding database\n",
    "'''\n",
    "\n",
    "# add persist_directory attribute to store the embeddings data\n",
    "db = Chroma.from_documents(documents=pages, embedding= embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "\n",
    "# persist_directory = 'chroma_db'\n",
    "# db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever\n",
    "A retriever is an interface that returns documents given an unstructured query.\n",
    "<br>\n",
    "Introduce chain type:stuff, refine, map_reduce\n",
    "<br>\n",
    "[Retrievers link](https://python.langchain.com/docs/modules/data_connection/retrievers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "# retriever = db.as_retriever(search_type= 'similarity')\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type='refine', retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword retrieval with prompt template\n",
    "\n",
    "ÂÆöÁæ©Ë¶ÅÈù¢ÊùøÊêúÂ∞ãÁöÑÈóúÈçµÂ≠óË©ûÔºåÂÆ¢Ë£Ω Prompt template \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_2019\\envs\\py39\\lib\\site-packages\\langchain\\llms\\openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "d:\\Anaconda3_2019\\envs\\py39\\lib\\site-packages\\langchain\\llms\\openai.py:716: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question, if you don't know the answer, leave it blank don't try to make up an answer.\n",
    "                {context}\n",
    "                Question: {question}\n",
    "                Answer in JSON representations\n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    \n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "rqa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)   \n",
    "# result = qa({\"query\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\" What is the display specifications?\n",
    "                include: company_name, product_name, size_inch,resolution,contrast,operation_temperature,sunlight_readable,antiglare,\n",
    "        \"\"\"\n",
    "        \n",
    "res = rqa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Control4 Corporation',\n",
       " 'product_name': 'Control4¬Æ T3 Series 7\" Tabletop Touch Screen',\n",
       " 'size_inch': 7,\n",
       " 'resolution': '1280 √ó 800',\n",
       " 'contrast': None,\n",
       " 'operation_temperature': '32 ~ 104ÀöF (0Àö ~ 40ÀöC)',\n",
       " 'sunlight_readable': None,\n",
       " 'antiglare': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "info = json.loads(res)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32efd6f67a841a19f53b75b62e5e32a4d4fde7ea0af6a18743f35490c2538f93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
