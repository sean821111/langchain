{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# requirements\\n!pip install langchain\\n!pip install openai\\n'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# requirements\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF Loader\n",
    "[Langchain PDF reference link](https://python.langchain.com/docs/modules/data_connection/document_loaders/how_to/pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key = \"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\"\n",
    "\n",
    "\n",
    "# loader = PyPDFLoader(\"example_data/rxi-web-panel-emerson.pdf\")\n",
    "# loader = PyPDFLoader(\"example_data/HEM-6232T Manual - Omron Healthcare.pdf\")\n",
    "# loader = PyPDFLoader(\"example_data/CONDENSED CATALOG - lotek.dk.pdf\")\n",
    "loader = PyPDFLoader(\"example_data/10-04-580-SPC - Wall-Smart.pdf\")\n",
    "\n",
    "# pages = loader.load_and_split()\n",
    "\n",
    "doc = loader.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Splliter\n",
    "\n",
    "[Dcument trasformers](https://python.langchain.com/docs/modules/data_connection/document_transformers/)\n",
    "<br>\n",
    "Ë∂ÖÈï∑ÊñáÊú¨ÁöÑÂàáÂâ≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# doc = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=1000)\n",
    "pages = splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n",
    "The Embeddings class is a class designed for interfacing with text embedding models. \n",
    "<br>\n",
    "[Text embedding models(e.g. openAI, huggingface)](https://python.langchain.com/docs/modules/data_connection/text_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store openai embedding vectors\n",
    "One of the most common ways to store and search over unstructured data is to embed it and store the resulting embedding vectors, and then at query time to embed the unstructured query and retrieve the embedding vectors that are 'most similar' to the embedded query. A vector store takes care of storing embedded data and performing vector search for you.\n",
    "<br>\n",
    "Vector store Êèê‰æõÂÑ≤Â≠ò‰ª•ÂèäÊ™¢Á¥¢ÈùûÁµêÊßãÂêëÈáèË≥áÊñôÔºåÈÄèÈÅé query Ê™¢Á¥¢ÊúÄÁõ∏‰ººÁöÑÂêëÈáè„ÄÇ\n",
    "\n",
    "[other langchain vector stores](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\n",
    "<br>\n",
    "[ü¶ú‚õìÔ∏è + Chroma](https://blog.langchain.dev/langchain-chroma/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "'''\n",
    "Chroma, the AI-native open-source embedding database\n",
    "'''\n",
    "\n",
    "\n",
    "# add persist_directory attribute to store the embeddings data\n",
    "db = Chroma.from_documents(documents=pages, embedding= embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "\n",
    "# persist_directory = 'chroma_db'\n",
    "# db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever\n",
    "A retriever is an interface that returns documents given an unstructured query.\n",
    "<br>\n",
    "Introduce chain type:stuff, refine, map_reduce\n",
    "<br>\n",
    "[Retrievers link](https://python.langchain.com/docs/modules/data_connection/retrievers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "# retriever = db.as_retriever(search_type= 'similarity')\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type='refine', retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword retrieval with prompt template\n",
    "\n",
    "ÂÆöÁæ©Ë¶ÅÈù¢ÊùøÊêúÂ∞ãÁöÑÈóúÈçµÂ≠óË©ûÔºåÂÆ¢Ë£Ω Prompt template \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question, if you don't know the answer, leave it blank don't try to make up an answer.\n",
    "\n",
    "                {context}\n",
    "                \n",
    "                Question: {question}\n",
    "                Answer in JSON representations\n",
    "                \"\"\"\n",
    "                \n",
    "                \n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    \n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "rqa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=db.as_retriever(), chain_type_kwargs=chain_type_kwargs)   \n",
    "# result = qa({\"query\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\" What is the display specifications? \n",
    "            include: company_name, product_name, size_inch,resolution,contrast,operation_temperature,sunlight_readable,antiglare\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "res = rqa.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company_name': 'Control4',\n",
       " 'product_name': 'T3 Series 7\" Tabletop Touch Screen',\n",
       " 'size_inch': 7,\n",
       " 'resolution': '1280 √ó 800',\n",
       " 'contrast': 'N/A',\n",
       " 'operation_temperature': '32 ~ 104ÀöF (0Àö ~ 40ÀöC)',\n",
       " 'sunlight_readable': 'No',\n",
       " 'antiglare': 'No'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "info = json.loads(res)\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32efd6f67a841a19f53b75b62e5e32a4d4fde7ea0af6a18743f35490c2538f93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
